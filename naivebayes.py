
"""
    The aim of this module is to implement the Naive Bayes classification algorithm
    for text classification.
    
    This algorithm will include:
    a feature extractor:
        this builds the contingency table used by the classifier
        it will take an array of features and their classes
    a classifier:
        this will use the contingency table generated by the feature extractor to
        predict the class of a new feature
"""

import sys
import os
import nltk


class Counter(dict):
    def __missing__(self, key):
        return 1


class NaiveBayes(object):
    def __init__(self, *args, **kwargs):
        self.features = None
        self.classes = None
        self.total_words = None

    def __str__(self):
        return "Cleverchuk's Simple Naive Bayes Classifier"

    def listWords(self, text):
        """
            utility method
        """
        words = map(str.lower, nltk.word_tokenize(text))
        for w in words: # n^2
            if len(w) < 3:
                words.pop(words.index(w)) 

        return words

    def train(self, feature_arr, class_arr):
        """
            param: feature_arr array of features only strings valid features
            param: class_arr array of classes for the features in feature_arr

            this method is used to created a virtual contingency table used to 
            calculate the probabilities for the Bayes theorem
        """
        self.features = {}  # a dictionary representing the contingency table
        self.classes = Counter()  # a dictionary for keeping count of class
        self.total_words = 0

        # validate data size
        if len(feature_arr) != len(class_arr):
            raise Exception(
                "length of feature_arr must equal length of class_arr")
        
        # validate data type
        if not all(type(item) is str for item in feature_arr) and \
            not all(type(item) is str for item in class_arr):
            raise ValueError("must be array of strings")

        for i in range(len(feature_arr)): # n^3
            words = self.listWords(feature_arr[i])

            # frequency of class
            if class_arr[i] not in self.classes:
                self.classes[class_arr[i]] = 1
            else:
                self.classes[class_arr[i]] += 1

            # aggregate word occurrence in each class
            for word in words:
                if word not in self.features:
                    counter = {}
                    for c in class_arr:
                        counter[c] = 0

                    self.features[word] = counter
                    self.total_words += 1  # aggregates the total observations in the table

                self.features[word][class_arr[i]] += 1

        return (self.features, self.classes, self.total_words)

    def classify(self, sentence):
        """
            param: sentence sentence to classify
            this method classifies a sentence
        """
        words = self.listWords(sentence)
        _class = None
        prob_f = 0

        for c in self.classes.keys(): # n^2
            # calculate P(C)
            prob_c = self.classes[c]/float(sum(self.classes.values()))  # P(C)
            prob_total = prob_c

            for w in words:
                if w in self.features:
                    # calculate P(W and C)
                    prob_w = self.features[w][c] / float(self.total_words)
                    prob_cond = prob_w/prob_c  # P(W|C)
                    prob = prob_cond*prob_w/prob_c  # P(C|W)
                    prob_total *= prob

                    if prob_f < prob_total:
                        prob_f = prob
                        _class = c

        return (_class, prob_f)



